{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchreid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ random crop (enlarge to 288x144 and crop 256x128)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root='reid-data',\n",
    "    sources='market1501',\n",
    "    targets='market1501',\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=32,\n",
    "    batch_size_test=100,\n",
    "    transforms=['random_flip', 'random_crop']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded pretrained weights from \"./log/resnet50/model/model.pth.tar-60\"\n"
     ]
    }
   ],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name='resnet50',\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss='softmax',\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "torchreid.utils.load_pretrained_weights(model, './log/resnet50/model/model.pth.tar-60')\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim='adam',\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = torchreid.engine.ImageSoftmaxEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    label_smooth=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Evaluating market1501 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 3368-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 3368-by-2048 matrix\n",
      "Speed: 0.0698 sec/batch\n",
      "Normalzing features with L2 norm ...\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Applying person re-ranking ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 77.5%\n",
      "CMC curve\n",
      "Rank-1  : 82.3%\n",
      "Rank-5  : 92.3%\n",
      "Rank-10 : 95.0%\n",
      "Rank-20 : 97.2%\n",
      "[ 72 622 321 ...  33  86  27]\n",
      "Stalling\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d02aa99e1f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnormalize_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrerank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvisrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/notebooks/deep-person-reid/torchreid/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, save_dir, max_epoch, start_epoch, print_freq, fixbase_epoch, open_layers, start_eval, eval_freq, test_only, dist_metric, normalize_feature, visrank, visrank_topk, use_metric_cuhk03, ranks, rerank)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0muse_metric_cuhk03\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metric_cuhk03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mranks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mrerank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             )\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/deep-person-reid/torchreid/engine/engine.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, dist_metric, normalize_feature, visrank, visrank_topk, save_dir, use_metric_cuhk03, ranks, rerank)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0muse_metric_cuhk03\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metric_cuhk03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mranks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mrerank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             )\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchreid/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/deep-person-reid/torchreid/engine/engine.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset_name, query_loader, gallery_loader, dist_metric, normalize_feature, visrank, visrank_topk, save_dir, use_metric_cuhk03, ranks, rerank)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'visrank_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisrank_topk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m             )\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/deep-person-reid/torchreid/utils/reidtools.py\u001b[0m in \u001b[0;36mvisualize_ranked_results\u001b[0;34m(distmat, dataset, data_type, width, height, save_dir, topk)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stalling'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mmkdir_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "engine.run(\n",
    "    save_dir='log/resnet50',\n",
    "    max_epoch=60,\n",
    "    eval_freq=10,\n",
    "    print_freq=10,\n",
    "    test_only=True,\n",
    "    #normalize_feature=True,\n",
    "    #rerank=True,\n",
    "    visrank=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
